{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "Example_file = \"C:/Users/Swami/Downloads/SpamData/SpamData/01_Processing/practice_email.txt\"\n",
    "Spam_1_path = \"C:/Users/Swami/Downloads/SpamData/SpamData/01_Processing/spam_assassin_corpus/spam_1\"\n",
    "Spam_2_path = \"C:/Users/Swami/Downloads/SpamData/SpamData/01_Processing/spam_assassin_corpus/spam_2\"\n",
    "Easy_Nonspam_1_path = \"C:/Users/Swami/Downloads/SpamData/SpamData/01_Processing/spam_assassin_corpus/easy_ham_1\"\n",
    "Easy_Nonspam_2_path = \"C:/Users/Swami/Downloads/SpamData/SpamData/01_Processing/spam_assassin_corpus/easy_ham_2\"\n",
    "\n",
    "DATA_JSON_FILE = \"C:/Users/Swami/Downloads/SpamData/SpamData/01_Processing/email_text-data.json\"\n",
    "Spam_Cat = 1\n",
    "Ham_Cat = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From exmh-workers-admin@redhat.com  Thu Aug 22 12:36:23 2002\n",
      "Return-Path: <exmh-workers-admin@spamassassin.taint.org>\n",
      "Delivered-To: zzzz@localhost.netnoteinc.com\n",
      "Received: from localhost (localhost [127.0.0.1])\n",
      "\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id D03E543C36\n",
      "\tfor <zzzz@localhost>; Thu, 22 Aug 2002 07:36:16 -0400 (EDT)\n",
      "Received: from phobos [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 12:36:16 +0100 (IST)\n",
      "Received: from listman.spamassassin.taint.org (listman.spamassassin.taint.org [66.187.233.211]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g7MBYrZ04811 for\n",
      "    <zzzz-exmh@spamassassin.taint.org>; Thu, 22 Aug 2002 12:34:53 +0100\n",
      "Received: from listman.spamassassin.taint.org (localhost.localdomain [127.0.0.1]) by\n",
      "    listman.redhat.com (Postfix) with ESMTP id 8386540858; Thu, 22 Aug 2002\n",
      "    07:35:02 -0400 (EDT)\n",
      "Delivered-To: exmh-workers@listman.spamassassin.taint.org\n",
      "Received: from int-mx1.corp.spamassassin.taint.org (int-mx1.corp.spamassassin.taint.org\n",
      "    [172.16.52.254]) by listman.redhat.com (Postfix) with ESMTP id 10CF8406D7\n",
      "    for <exmh-workers@listman.redhat.com>; Thu, 22 Aug 2002 07:34:10 -0400\n",
      "    (EDT)\n",
      "Received: (from mail@localhost) by int-mx1.corp.spamassassin.taint.org (8.11.6/8.11.6)\n",
      "    id g7MBY7g11259 for exmh-workers@listman.redhat.com; Thu, 22 Aug 2002\n",
      "    07:34:07 -0400\n",
      "Received: from mx1.spamassassin.taint.org (mx1.spamassassin.taint.org [172.16.48.31]) by\n",
      "    int-mx1.corp.redhat.com (8.11.6/8.11.6) with SMTP id g7MBY7Y11255 for\n",
      "    <exmh-workers@redhat.com>; Thu, 22 Aug 2002 07:34:07 -0400\n",
      "Received: from ratree.psu.ac.th ([202.28.97.6]) by mx1.spamassassin.taint.org\n",
      "    (8.11.6/8.11.6) with SMTP id g7MBIhl25223 for <exmh-workers@redhat.com>;\n",
      "    Thu, 22 Aug 2002 07:18:55 -0400\n",
      "Received: from delta.cs.mu.OZ.AU (delta.coe.psu.ac.th [172.30.0.98]) by\n",
      "    ratree.psu.ac.th (8.11.6/8.11.6) with ESMTP id g7MBWel29762;\n",
      "    Thu, 22 Aug 2002 18:32:40 +0700 (ICT)\n",
      "Received: from munnari.OZ.AU (localhost [127.0.0.1]) by delta.cs.mu.OZ.AU\n",
      "    (8.11.6/8.11.6) with ESMTP id g7MBQPW13260; Thu, 22 Aug 2002 18:26:25\n",
      "    +0700 (ICT)\n",
      "From: Robert Elz <kre@munnari.OZ.AU>\n",
      "To: Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n",
      "Cc: exmh-workers@spamassassin.taint.org\n",
      "Subject: Re: New Sequences Window\n",
      "In-Reply-To: <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
      "References: <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
      "    <1029882468.3116.TMDA@deepeddy.vircio.com> <9627.1029933001@munnari.OZ.AU>\n",
      "    <1029943066.26919.TMDA@deepeddy.vircio.com>\n",
      "    <1029944441.398.TMDA@deepeddy.vircio.com>\n",
      "MIME-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Message-Id: <13258.1030015585@munnari.OZ.AU>\n",
      "X-Loop: exmh-workers@spamassassin.taint.org\n",
      "Sender: exmh-workers-admin@spamassassin.taint.org\n",
      "Errors-To: exmh-workers-admin@spamassassin.taint.org\n",
      "X-Beenthere: exmh-workers@spamassassin.taint.org\n",
      "X-Mailman-Version: 2.0.1\n",
      "Precedence: bulk\n",
      "List-Help: <mailto:exmh-workers-request@spamassassin.taint.org?subject=help>\n",
      "List-Post: <mailto:exmh-workers@spamassassin.taint.org>\n",
      "List-Subscribe: <https://listman.spamassassin.taint.org/mailman/listinfo/exmh-workers>,\n",
      "    <mailto:exmh-workers-request@redhat.com?subject=subscribe>\n",
      "List-Id: Discussion list for EXMH developers <exmh-workers.spamassassin.taint.org>\n",
      "List-Unsubscribe: <https://listman.spamassassin.taint.org/mailman/listinfo/exmh-workers>,\n",
      "    <mailto:exmh-workers-request@redhat.com?subject=unsubscribe>\n",
      "List-Archive: <https://listman.spamassassin.taint.org/mailman/private/exmh-workers/>\n",
      "Date: Thu, 22 Aug 2002 18:26:25 +0700\n",
      "\n",
      "\n",
      "Dear Mr Still\n",
      "\n",
      "Good tidings to you and all your staff for the festive season ahead (Christmas).\n",
      "Now to the crux of the matter-in-hand: I am a fully qualified Santa Claus and am wondering whether you might consider me to run my own \"Santa's Grotto\" in your store.\n",
      "But WAIT! You're probably thinking: \"What makes him so special?\"\n",
      "Well, first of all, I have made several changes to the characterisation of Father Christmas. Rather than greeting the children with shouts of \"Ho, ho, ho!\" I prefer to whisper the phrase \"Dependence is not unfathomable in this cruel world we live in\". In addition, my gifts are ALL hand-made, ranging from felt hoops to vanilla-pod holders.\n",
      "You will note also, from the enclosed sketch, that I have radically redesigned Santa's outfit and have renamed my character \"Lord Buckles\". Would you be interested in employing me? I promise NEVER to let you down.\n",
      "I look forward to hearing from you.\n",
      "\n",
      "Best wishes\n",
      "Robin Cooper\n",
      "[Excerpt from the book: The Timewaster Letters by Robin Cooper]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stream = open(Example_file, encoding='latin-1')\n",
    "message = stream.read()\n",
    "stream.close()\n",
    "\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display mail body from the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dear Mr Still\n",
      "\n",
      "\n",
      "\n",
      "Good tidings to you and all your staff for the festive season ahead (Christmas).\n",
      "\n",
      "Now to the crux of the matter-in-hand: I am a fully qualified Santa Claus and am wondering whether you might consider me to run my own \"Santa's Grotto\" in your store.\n",
      "\n",
      "But WAIT! You're probably thinking: \"What makes him so special?\"\n",
      "\n",
      "Well, first of all, I have made several changes to the characterisation of Father Christmas. Rather than greeting the children with shouts of \"Ho, ho, ho!\" I prefer to whisper the phrase \"Dependence is not unfathomable in this cruel world we live in\". In addition, my gifts are ALL hand-made, ranging from felt hoops to vanilla-pod holders.\n",
      "\n",
      "You will note also, from the enclosed sketch, that I have radically redesigned Santa's outfit and have renamed my character \"Lord Buckles\". Would you be interested in employing me? I promise NEVER to let you down.\n",
      "\n",
      "I look forward to hearing from you.\n",
      "\n",
      "\n",
      "\n",
      "Best wishes\n",
      "\n",
      "Robin Cooper\n",
      "\n",
      "[Excerpt from the book: The Timewaster Letters by Robin Cooper]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stream = open(Example_file, encoding='latin-1')\n",
    "\n",
    "is_body = False\n",
    "lines = []\n",
    "for line in stream:\n",
    " if is_body:\n",
    "  lines.append(line)\n",
    " elif line =='\\n': # if there is a blank line between paragraph, if it is new line then it is body of mail\n",
    "   is_body = True\n",
    "   \n",
    "stream.close()\n",
    "email_body = '\\n' .join(lines) # new line charac makes to display form list like a paragraph\n",
    "print(email_body)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_squares(N) :\n",
    "    for my_number in range(N):\n",
    "     yield my_number ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0>1>4>9>16>"
     ]
    }
   ],
   "source": [
    "for i in generate_squares(5):\n",
    "    print(i, end='>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Email body extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_body_generator(path):\n",
    " for root, dirnames, filenames in walk(path):\n",
    "     for file_name in filenames:\n",
    "        filepath = join(root, file_name)\n",
    "\n",
    "        stream = open(filepath, encoding='latin-1')\n",
    "\n",
    "        is_body = False\n",
    "        lines = []\n",
    "        for line in stream:\n",
    "           if is_body:\n",
    "             lines.append(line)\n",
    "           elif line =='\\n': # if there is a blank line between paragraph, if it is new line then it is body of mail\n",
    "            is_body = True\n",
    "        \n",
    "        stream.close()\n",
    "        email_body = '\\n' .join(lines) # new line charac makes to display form list like a paragraph\n",
    "        yield file_name, email_body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_directory(path, classification):\n",
    "    rows = []\n",
    "    row_names = []\n",
    "    \n",
    "    for file_name, email_body in email_body_generator(path):\n",
    "        rows.append({'MESSAGE': email_body, 'CATEGORY': classification})\n",
    "        row_names.append(file_name)\n",
    "        \n",
    "return pd.DataFrame(rows, index=row_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3648\\730344890.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mspam_emails\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_from_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSpam_1_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mspam_emails\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspam_emails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_from_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSpam_2_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mspam_emails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Swami\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         ):\n\u001b[0;32m   6203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "spam_emails = df_from_directory(Spam_1_path, 1)\n",
    "spam_emails = spam_emails.append(df_from_directory(Spam_2_path, 1))\n",
    "spam_emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = df_from_directory(EASY_NONSPAM_1_PATH, HAM_CAT)\n",
    "ham_emails = ham_emails.append(df_from_directory(EASY_NONSPAM_2_PATH, HAM_CAT))\n",
    "ham_emails.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ham_emails' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[229], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([spam_emails, \u001b[43mham_emails\u001b[49m])\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of entire dataframe is\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ham_emails' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.concat([spam_emails, ham_emails])\n",
    "print('Shape of entire dataframe is', data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning : Checking for Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any message bodies are null\n",
    "data['MESSAGE'].isnull().values.any()\n",
    " # we have no empty values in message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# empty string will be like this \" \", \n",
    "len (\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are empty emails (string length zero).\n",
    "(data.MESSAGE.str.len() == 0).any().sum() #( how many have zero strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how would you check the no. of entries with null/None values\n",
    "data.MESSAGE.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOCATE Empty Mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.MESSAGE.str.len() == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " data.index.get_loc('cmds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove system file entries from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =data.drop(['cmds'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD document ID to track Emails in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ids = range(0, len(data.index))\n",
    "data['DOC_ID'] = document_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['FILE_NAME'] = data.index\n",
    "data.set_index('DOC_ID', inplace=True) # shows as seperate index\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to File using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json(DATA_JSON_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Spam Messages Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.CATEGORY.value_counts() # displays 2 category spam and ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_spam = data.CATEGORY.value_counts()[1] # selecting spam and ham category\n",
    "amount_of_ham = data.CATEGORY.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = ['Spam', 'Legit_Mail']\n",
    "sizes = [amount_of_spam, amount_of_ham]\n",
    "plt.figure(figsize=(2,2), dpi= 227) # density of pixels per inch\n",
    "plt.pie(sizes, labels=category_names, textprops={'fontsize': 6}, \n",
    "startangle=10, auto = '%1.1f%%', explode=[0,0.1]) # startangle changes pie position, \n",
    "#1.1 shows one decimal point, explode means seprate the pie with one another.\n",
    "\n",
    "# draw  circle\n",
    "plt.Circle((0,0), radius=0.6, fc='white')\n",
    "plt.gca().add_artist(center_circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "Text processing ( Tokenizer & Stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt') # it downloads some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words - at, of the ,a at, and dont meain word seperation for NLP\n",
    "nltk.download('stopwords' ) # downloads\n",
    "stop_words = set(stopwords.words('english'))\n",
    "if 'this' in stop_words: print('Found it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \" All work and no play makes jack a dull boy.\"\n",
    "word = word_tokenize(msg.lower())\n",
    "filtered_words = []\n",
    "# Append non-stop words to filtered words\n",
    "for word in words:\n",
    "    if word not in stop_words:\n",
    "        filtered_words.append(word)\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Word Stemming (like fishing, fished, fisher are came form FISH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \" All work and no play makes jack a dull boy. \\\n",
    "    Nobody Expect this! \"\n",
    "word = word_tokenize(msg.lower())\n",
    "\n",
    "stemmer = PorterStemmer( )\n",
    "stemmer = SnowballStemmer('Finnish') # to stemm word which is not english u can provide the language here\n",
    "filtered_words = []\n",
    "# Append non-stop words to filtered words\n",
    "for word in words:\n",
    "    if word not in stop_words:\n",
    "        stemmed_word = stemmer.stem(word)\n",
    "        filtered_words.append(stemmed_word) # here makes is stemmed to make.\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = ' All work and no play makes jack a dull boy.???? \\\n",
    "    Nobody Expect this! '\n",
    "word = word_tokenize(msg.lower())\n",
    "stemmer = SnowballStemmer('Finnish') # to stemm word which is not english u can provide the language here\n",
    "filtered_words = []\n",
    "# Append non-stop words to filtered words\n",
    "for word in words:\n",
    "    if word not in stop_words and word.isalpha(): # isalpha identifies punctuation \n",
    "        stemmed_word = stemmer.stem(word)\n",
    "        filtered_words.append(stemmed_word) # here makes is stemmed to make.\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing HTML tags from E-MAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.at[2, 'MESSAGE'] # This is at 2nd index and MESSAGE Column\n",
    "soup = BeautifulSoup(data.at[2, 'MESSAGE'], 'html.parser')\n",
    "print(soup.prettify() ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.get_text() # --> removes all html tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for Email Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifies func to remove HTML tags, then test on Email with DOC_ID 2\n",
    "  def clean_msg_no_html( message, stemmer=PorterStemmer(), \n",
    "                     stop_words=set(stopwords.words('english'))):\n",
    "         \n",
    "         # Remove Html Tags\n",
    "        soup = BeautifulSoup(message, 'html.parser')\n",
    "        cleaned_text =  soup.get_text( ) \n",
    "        # Converts  to lower case and split the words\n",
    "        words = word_tokenize(cleaned_text.lower())\n",
    "        \n",
    "        filtered_words = []\n",
    "\n",
    "        for word in words:\n",
    "            # Remove the stop words and punctuation\n",
    "             if word not in stop_words and word.isalpha():\n",
    "                filtered_word.append(stemmer.stem(word))\n",
    "\n",
    "\n",
    "         return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_msg_no_html(data.at[2, 'MESSAGE']) #giving this input as 2nd \n",
    "#Doc_id and its message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Applying Cleaning and tokenization to all messages\n",
    "\n",
    " Slicing Dataframes and Series & Creating Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " data.iat[2,  1] #2nd one is column number 1 is message column\n",
    " #, 0 is category column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0:2] # get rows of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_emails = data.MESSAGE.iloc[0:3]\n",
    "\n",
    "nested_list = first_emails.apply(clean_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
